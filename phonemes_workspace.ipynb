{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9149bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5780de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for colab -- ugh\n",
    "def load_py(filename, alias: str = None):\n",
    "    \"\"\"Handle importing and reloading modules when in colab\"\"\"\n",
    "    import requests, importlib, sys\n",
    "    if not filename.endswith(\".py\"): filename += \".py\"\n",
    "    \n",
    "    if 'google.colab' in sys.modules:\n",
    "        if '/content/' not in sys.path:\n",
    "            sys.path.insert(0, '/content/')\n",
    "\n",
    "        url = f\"https://raw.githubusercontent.com/BenAF002/dabble_bot_v2_dev/refs/heads/main/phonemes/{filename}\"\n",
    "        code = requests.get(url).text\n",
    "\n",
    "        # write to /content for colab\n",
    "        destination = f\"/content/{filename}\"\n",
    "        with open(destination, \"w\") as f:\n",
    "            f.write(code)\n",
    "\n",
    "    # handle module reloading\n",
    "    module_name = filename[:-3] # Strip the .py extension\n",
    "    if alias in globals():\n",
    "        importlib.reload(globals()[alias])\n",
    "    elif module_name in globals():\n",
    "        importlib.reload(globals()[module_name])\n",
    "    else:\n",
    "        if alias is not None:\n",
    "            globals()[alias] = importlib.import_module(module_name)\n",
    "        else:\n",
    "            globals()[module_name] = importlib.import_module(module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6653d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [\"encoder\", \"decoder\", \"dataset\", \"train\"]\n",
    "for module in modules:\n",
    "    load_py(module + \".py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82fa92ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93131, 23283)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = dataset.Words()\n",
    "train_data, test_data = wd.train_test_split(0.8)\n",
    "\n",
    "train_data.__len__(), test_data.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d5bd4",
   "metadata": {},
   "source": [
    "## BERT Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be84dbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n params: 114,610\n"
     ]
    }
   ],
   "source": [
    "bert = encoder.EncoderBERT(n_emb=64, exp=4, n_heads=2, n_blocks=2, dropout=0.0, pool='cls', mask_attn=True)\n",
    "\n",
    "print(f\"n params: {sum(p.numel() for p in bert.parameters()):,.0f}\")\n",
    "if bert.device == 'cuda': \n",
    "    bert.to('cuda')\n",
    "    bert = torch.compile(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4554d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  return _C._get_float32_matmul_precision()\n",
      "W1217 01:44:15.258000 3324 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 - Train Loss: 0.3616, Test Loss: 0.2194 | ETA: 30 min, 14 sec\n",
      "Epoch 2/40 - Train Loss: 0.2027, Test Loss: 0.1934 | ETA: 15 min, 30 sec\n",
      "Epoch 3/40 - Train Loss: 0.1855, Test Loss: 0.1805 | ETA: 10 min, 39 sec\n",
      "Epoch 4/40 - Train Loss: 0.1733, Test Loss: 0.1680 | ETA: 8 min, 9 sec\n",
      "Epoch 5/40 - Train Loss: 0.1610, Test Loss: 0.1566 | ETA: 6 min, 38 sec\n",
      "Epoch 6/40 - Train Loss: 0.1504, Test Loss: 0.1475 | ETA: 5 min, 37 sec\n",
      "Epoch 7/40 - Train Loss: 0.1420, Test Loss: 0.1396 | ETA: 4 min, 52 sec\n",
      "Epoch 8/40 - Train Loss: 0.1349, Test Loss: 0.1339 | ETA: 4 min, 18 sec\n",
      "Epoch 9/40 - Train Loss: 0.1287, Test Loss: 0.1276 | ETA: 3 min, 51 sec\n",
      "Epoch 10/40 - Train Loss: 0.1231, Test Loss: 0.1221 | ETA: 3 min, 29 sec\n",
      "Epoch 11/40 - Train Loss: 0.1178, Test Loss: 0.1170 | ETA: 3 min, 10 sec\n",
      "Epoch 12/40 - Train Loss: 0.1137, Test Loss: 0.1135 | ETA: 2 min, 54 sec\n",
      "Epoch 13/40 - Train Loss: 0.1101, Test Loss: 0.1098 | ETA: 2 min, 40 sec\n",
      "Epoch 14/40 - Train Loss: 0.1071, Test Loss: 0.1083 | ETA: 2 min, 28 sec\n",
      "Epoch 15/40 - Train Loss: 0.1045, Test Loss: 0.1057 | ETA: 2 min, 17 sec\n",
      "Epoch 16/40 - Train Loss: 0.1022, Test Loss: 0.1031 | ETA: 2 min, 8 sec\n",
      "Epoch 17/40 - Train Loss: 0.1001, Test Loss: 0.1018 | ETA: 1 min, 59 sec\n",
      "Epoch 18/40 - Train Loss: 0.0980, Test Loss: 0.0995 | ETA: 1 min, 50 sec\n",
      "Epoch 19/40 - Train Loss: 0.0963, Test Loss: 0.0977 | ETA: 1 min, 42 sec\n",
      "Epoch 20/40 - Train Loss: 0.0946, Test Loss: 0.0974 | ETA: 1 min, 35 sec\n",
      "Epoch 21/40 - Train Loss: 0.0930, Test Loss: 0.0949 | ETA: 1 min, 28 sec\n",
      "Epoch 22/40 - Train Loss: 0.0917, Test Loss: 0.0940 | ETA: 1 min, 22 sec\n",
      "Epoch 23/40 - Train Loss: 0.0903, Test Loss: 0.0927 | ETA: 1 min, 16 sec\n",
      "Epoch 24/40 - Train Loss: 0.0891, Test Loss: 0.0924 | ETA: 1 min, 10 sec\n",
      "Epoch 25/40 - Train Loss: 0.0880, Test Loss: 0.0906 | ETA: 1 min, 5 sec\n",
      "Epoch 26/40 - Train Loss: 0.0868, Test Loss: 0.0897 | ETA: 0 min, 60 sec\n",
      "Epoch 27/40 - Train Loss: 0.0858, Test Loss: 0.0892 | ETA: 0 min, 54 sec\n",
      "Epoch 28/40 - Train Loss: 0.0847, Test Loss: 0.0882 | ETA: 0 min, 50 sec\n",
      "Epoch 29/40 - Train Loss: 0.0839, Test Loss: 0.0872 | ETA: 0 min, 45 sec\n",
      "Epoch 30/40 - Train Loss: 0.0831, Test Loss: 0.0869 | ETA: 0 min, 40 sec\n",
      "Epoch 31/40 - Train Loss: 0.0821, Test Loss: 0.0858 | ETA: 0 min, 36 sec\n",
      "Epoch 32/40 - Train Loss: 0.0813, Test Loss: 0.0847 | ETA: 0 min, 31 sec\n",
      "Epoch 33/40 - Train Loss: 0.0807, Test Loss: 0.0854 | ETA: 0 min, 27 sec\n",
      "Epoch 34/40 - Train Loss: 0.0800, Test Loss: 0.0835 | ETA: 0 min, 23 sec\n",
      "Epoch 35/40 - Train Loss: 0.0793, Test Loss: 0.0830 | ETA: 0 min, 19 sec\n",
      "Epoch 36/40 - Train Loss: 0.0786, Test Loss: 0.0831 | ETA: 0 min, 15 sec\n",
      "Epoch 37/40 - Train Loss: 0.0779, Test Loss: 0.0820 | ETA: 0 min, 11 sec\n",
      "Epoch 38/40 - Train Loss: 0.0774, Test Loss: 0.0818 | ETA: 0 min, 7 sec\n",
      "Epoch 39/40 - Train Loss: 0.0768, Test Loss: 0.0807 | ETA: 0 min, 4 sec\n",
      "Epoch 40/40 - Train Loss: 0.0763, Test Loss: 0.0810 | ETA: 0 min, 0 sec\n"
     ]
    }
   ],
   "source": [
    "# try training\n",
    "optimizer = torch.optim.AdamW(bert.parameters(), lr=6e-4)\n",
    "\n",
    "train.training_loop(\n",
    "    model=bert, \n",
    "    train_data=train_data, \n",
    "    test_data=test_data,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=256,\n",
    "    n_epochs=40, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf7f75",
   "metadata": {},
   "source": [
    "## GRU Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4f9648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model param devices: {device(type='cuda', index=0)}\n",
      "n params: 295,968\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(phon.decoder)\n",
    "\n",
    "gru = phon.decoder.DecoderGRU(input_size=(64+50), hidden_size=256)\n",
    "gru.to(torch.device('cuda'))\n",
    "gru = torch.compile(gru)\n",
    "params_devices = {p.device for p in gru.parameters()}\n",
    "print(\"model param devices:\", params_devices)\n",
    "print(f\"n params: {sum(p.numel() for p in gru.parameters()):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a9915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1216 19:30:05.520000 22364 site-packages\\torch\\_inductor\\utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([256, 50]) torch.Size([256, 18])\n",
      "torch.float32 torch.int32\n",
      "torch.Size([203, 50]) torch.Size([203, 18])\n",
      "Epoch 1/1 - Train Loss: 1.6581, Test Loss: 1.1283 | ETA: 0 min, 0 sec\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(gru.parameters(), lr=6e-4)\n",
    "\n",
    "importlib.reload(phon.train)\n",
    "phon.train.training_loop(\n",
    "    model=gru, \n",
    "    train_data=train, \n",
    "    test_data=test, \n",
    "    optimizer=optimizer,\n",
    "    batch_size=256,\n",
    "    n_epochs=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0890f279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guzek  :  gueg\n",
      "detach  :  datidt\n",
      "cavagnaro  :  arkowango\n",
      "creech  :  kurie\n",
      "foose  :  faues\n",
      "boasting  :  boottyming\n",
      "discussed  :  decesfud\n",
      "fredericksen  :  vertircon\n",
      "knickknacks  :  cnouricac\n",
      "washington  :  awithon\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(test, batch_size=32, shuffle=True)\n",
    "yb, xb = next(iter(dl))\n",
    "yb, xb = yb.to(gru.device), xb.to(gru.device)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\n",
    "        wd.dec(yb[i]), ' : ',\n",
    "        wd.dec(gru.predict(xb[i].unsqueeze(1).T)[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1ba8e",
   "metadata": {},
   "source": [
    "## Transformer Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba3ff1",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b8d90a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
