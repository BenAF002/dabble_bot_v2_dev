{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11fdf6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "# from phonemes import encoder\n",
    "# from phonemes import decoder\n",
    "# from phonemes import dataset\n",
    "import tiktoken\n",
    "token_enc = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f9045b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m importlib.reload(\u001b[43mencoder\u001b[49m)\n\u001b[32m      2\u001b[39m path = Path(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbenak\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m bert_state_dict = torch.load(path / \u001b[33m'\u001b[39m\u001b[33mphonemes_bert.pth\u001b[39m\u001b[33m'\u001b[39m, weights_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(encoder)\n",
    "path = Path(r\"C:\\Users\\benak\\Downloads\")\n",
    "\n",
    "bert_state_dict = torch.load(path / 'phonemes_bert.pth', weights_only=True)\n",
    "gru_state_dict = torch.load(path / 'phonemes_gru.pth', weights_only=True)\n",
    "\n",
    "bert = encoder.EncoderBERT(n_emb=64, exp=4, n_heads=2, n_blocks=2, dropout=0.0, pool='cls', mask_attn=True)\n",
    "gru = decoder.DecoderGRU(input_size=(64+50), hidden_size=128)\n",
    "bert_state = {k.replace('_orig_mod.', ''): v for k, v in bert_state_dict.items()}\n",
    "gru_state = {k.replace('_orig_mod.', ''): v for k, v in gru_state_dict.items()}\n",
    "bert.load_state_dict(bert_state)\n",
    "gru.load_state_dict(gru_state)\n",
    "bert.eval(), gru.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = dataset.Words()  # dataset of words and phonetic embeddings - accessible through .mappings dict\n",
    "def wenc(word): return wd.enc(word).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599f84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1482, -0.4275,  0.4877, -0.1933, -0.0583, -0.1747, -0.0392,  0.2760,\n",
       "          0.2529, -0.2938,  0.2242,  0.4975, -0.7377, -0.4148,  0.3168, -0.5848,\n",
       "          0.0058, -0.1914,  0.0914, -0.1985, -0.1735,  0.2365, -0.0322, -0.1618,\n",
       "         -0.5113, -0.0505, -0.0313, -0.5150,  0.0351,  0.7522,  0.6980,  0.1678,\n",
       "         -0.3494, -0.3898, -0.9819,  0.1042,  0.3944, -0.3385,  0.5397, -0.1283,\n",
       "         -0.4749,  0.3122,  0.2301,  0.0791,  0.2777,  0.0676,  0.0225,  0.3422,\n",
       "         -0.2355,  0.2503]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert(wenc('aardvark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class PhoneticJumbler:\n",
    "    def __init__(self, words_dataset, encoder, decoder = None, n_neighbors: int = 5):\n",
    "        self.wd = words_dataset\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.nbrs = (\n",
    "            NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "            .fit(self.wd.embeddings)\n",
    "        )\n",
    "    \n",
    "    def find_closest_words(self, emb):\n",
    "        distances, indices = self.nbrs.kneighbors(emb)\n",
    "        words = list(self.wd.mappings.keys())\n",
    "        return [words[i] for i in indices[0]]\n",
    "    \n",
    "    def jumble(self, word: str, use_nn: bool = True):\n",
    "        \"\"\"\n",
    "        Get phonetically similar words for fine-tuning\n",
    "        \"\"\"\n",
    "        # try to get actual phonetic embedding, use encoder otherwise\n",
    "        try:\n",
    "            emb = self.wd.mappings.get(word, self.encoder(wenc(word)))\n",
    "            emb = emb.reshape(1, -1)\n",
    "            \n",
    "            if use_nn or self.decoder is None:\n",
    "                emb = emb.detach().numpy()\n",
    "                return random.choice(self.find_closest_words(emb))\n",
    "            else:\n",
    "                return wd.dec(self.decoder.predict(emb).reshape(-1))\n",
    "        except Exception as e:\n",
    "            print(f\"Error jumbling word '{word}': {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "616d90d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'una'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jumbler = PhoneticJumbler(wd, bert, gru)\n",
    "jumbler.jumble('eunoia', use_nn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de8f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\benak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: (n) the vertical force exerted by a mass as a result of gravity\n",
      "1: (n) sports equipment used in calisthenic exercises and weightlifting; it is not attached to anything and is raised and lowered by use of the hands and arms\n",
      "2: (n) the relative importance granted to something\n",
      "3: (n) an artifact that is heavy\n",
      "4: (n) an oppressive feeling of heavy force\n",
      "5: (n) a system of units used to express the weight of something\n",
      "6: (n) a unit used to measure weight\n",
      "7: (n) (statistics) a coefficient assigned to elements of a frequency distribution in order to represent their relative importance\n",
      "8: (v) weight down with a load\n",
      "9: (v) present with a bias\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "assert(nltk.download('wordnet'))\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# yield sample definitions from word \"weights\"\n",
    "for i,s in enumerate(wn.synsets('weights')):\n",
    "    print(f'{i}: ({s.pos()}) {s.definition()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d634cdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weights', 'the vertical force exerted by a mass as a result of gravity'),\n",
       " ('weights',\n",
       "  'sports equipment used in calisthenic exercises and weightlifting; it is not attached to anything and is raised and lowered by use of the hands and arms'),\n",
       " ('weights', 'the relative importance granted to something'),\n",
       " ('weights', 'an artifact that is heavy'),\n",
       " ('weights', 'an oppressive feeling of heavy force'),\n",
       " ('weights', 'a system of units used to express the weight of something'),\n",
       " ('weights', 'a unit used to measure weight'),\n",
       " ('weights',\n",
       "  '(statistics) a coefficient assigned to elements of a frequency distribution in order to represent their relative importance'),\n",
       " ('weights', 'weight down with a load'),\n",
       " ('weights', 'present with a bias')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'weights'\n",
    "\n",
    "df = [(w, s.definition()) for s in wn.synsets(w)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader compatible datasets for training and validation\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "pad_token = token_enc.max_token_value + 1  # add padding token\n",
    "\n",
    "class DefData:\n",
    "    def __init__(self):\n",
    "        # nested dict -- {word: {idx: (def, tokenized_def)}}\n",
    "        self.df = {}\n",
    "        self.max_def_len = 0\n",
    "        for w in wn.all_lemma_names():\n",
    "            if w.isalpha():\n",
    "                inner_dict = {}\n",
    "                for i,s in enumerate(wn.synsets(w)):\n",
    "                    definition = s.definition()\n",
    "                    token_def = token_enc.encode(definition)\n",
    "                    inner_dict[i] = [definition, token_def]\n",
    "                    if (def_len:=len(token_def)) > self.max_def_len: \n",
    "                        self.max_def_len = def_len\n",
    "                self.df[w] = inner_dict\n",
    "\n",
    "        # distinct pairs for train-test splits\n",
    "        self.words, self.token_defs = [], []\n",
    "        for w in self.df.keys():\n",
    "            for d in self.df[w]:\n",
    "                self.pad_def(self.df[w][d][1])  # pad tokenized definitions\n",
    "                self.words.append(w)\n",
    "                self.token_defs.append(self.df[w][d][1])\n",
    "        \n",
    "        # cast to indexable datastructures\n",
    "        self.words = np.array(self.words)\n",
    "        self.token_defs = torch.tensor(self.token_defs)\n",
    "\n",
    "    def pad_def(self, tokenized_definition):\n",
    "        \"\"\"Pad tokenized definition up to max definition length in dataset\"\"\"\n",
    "        tokenized_definition.extend(\n",
    "            [token_enc.max_token_value]  # eos token\n",
    "            + [pad_token] * (self.max_def_len - len(tokenized_definition))\n",
    "        )\n",
    "\n",
    "    def train_test_split(self, train_pct: float = 0.8, jumble_pct: float = 0.4):\n",
    "        \"\"\"\n",
    "        Split dataset into training and testing sets\n",
    "        Splits all word-definition pairs, so the same word may be in train and test set w/ different defs\n",
    "        \"\"\"\n",
    "        total_words = len(self.df.keys())\n",
    "        indices = np.random.permutation(total_words)\n",
    "        train_idx = indices[:int(total_words * train_pct)]\n",
    "        test_idx = indices[int(total_words * train_pct):]\n",
    "\n",
    "        train_data = DefDataSplit(dataset=self, indices=train_idx, jumble_pct=jumble_pct)\n",
    "        test_data = DefDataSplit(dataset=self, indices=test_idx)\n",
    "\n",
    "        return train_data, test_data\n",
    "\n",
    "\n",
    "class DefDataSplit(Dataset):\n",
    "    def __init__(self, dataset: DefData, indices, jumble_pct: float = None):\n",
    "        super().__init__()\n",
    "        self.dd = dataset\n",
    "        self.jumble_pct = jumble_pct\n",
    "        self.jumbler = jumbler\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # phonetically mask word at random with jumble_pct probability\n",
    "        rng = np.random.default_rng()\n",
    "        if self.jumble_pct is None or self.jumble_pct == 0.0:\n",
    "            word = self.words[idx]\n",
    "        elif (rng.random() < self.jumble_pct):\n",
    "                word = jumbler.jumble(word, use_nn=True)\n",
    "        else:\n",
    "            word = self.words[idx]\n",
    "        \n",
    "        prefix = torch.tensor(token_enc.encode(f\"The definition of {word} is:\"))\n",
    "        token_def = torch.cat([prefix, self.token_defs[idx]])\n",
    "        token_def = F.pad(\n",
    "            token_def, (0, 256 - len(token_def)),  # 256 is friendly and well above longest def\n",
    "            'constant', pad_token\n",
    "        )\n",
    "        return word, token_def \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4e0dcfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DefData()\n",
    "train_data, test_data = dd.train_test_split(train_pct=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537382fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for colab -- ugh\n",
    "def load_py(filename, alias: str = None):\n",
    "    \"\"\"Handle importing and reloading modules when in colab\"\"\"\n",
    "    import requests, importlib, sys\n",
    "    if not filename.endswith(\".py\"): filename += \".py\"\n",
    "    \n",
    "    if 'google.colab' in sys.modules:\n",
    "        if '/content/' not in sys.path:\n",
    "            sys.path.insert(0, '/content/')\n",
    "\n",
    "        url = f\"https://raw.githubusercontent.com/BenAF002/dabble_bot_v2_dev/refs/heads/main/{filename}\"\n",
    "        code = requests.get(url).text\n",
    "\n",
    "        # write to /content for colab\n",
    "        destination = f\"/content/{filename}\"\n",
    "        with open(destination, \"w\") as f:\n",
    "            f.write(code)\n",
    "\n",
    "    # handle module reloading\n",
    "    module_name = filename[:-3] # Strip the .py extension\n",
    "    module_name = module_name.rpartition('/')[-1]  # get substring after last backslash, if exists\n",
    "    if alias in globals():\n",
    "        importlib.reload(globals()[alias])\n",
    "    elif module_name in globals():\n",
    "        importlib.reload(globals()[module_name])\n",
    "    else:\n",
    "        if alias is not None:\n",
    "            globals()[alias] = importlib.import_module(module_name)\n",
    "        else:\n",
    "            globals()[module_name] = importlib.import_module(module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4e7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_py('dabble_gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8dfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dabble_gpt\n",
    "importlib.reload(dabble_gpt)\n",
    "\n",
    "gpt = dabble_gpt.GPT().from_pretrained(model_type='gpt2', lora_rank=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceddce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = gpt.generate(seq=\"Scientists recently discovered a herd of fuzzy \", max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "415f2498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scientists recently discovered a herd of fuzzy vernaculars in a Siberian area. \"Their hair was quite wide,\" says the paleontologist Dr. Anna R. Bekkova, who led the study.\\n\\nIn her laboratory, the team collected fossils that were too narrow for the study. They determined that these were probably the earliest prunus ever spotted in this region. The team also found traces of an amphora called the pinnacles.\\n\\n\"An amphora isn\\'t a very large animal,\" says Ber'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63cbcc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3]).reshape(1, -1)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18cea6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[-1, -1].reshape(1) #, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77db0be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <class 'dabble_gpt.GPT'>\n",
      "transformer <class 'torch.nn.modules.container.ModuleDict'>\n",
      "transformer.wte <class 'torch.nn.modules.sparse.Embedding'>\n",
      "transformer.wpe <class 'torch.nn.modules.sparse.Embedding'>\n",
      "transformer.h <class 'torch.nn.modules.container.ModuleList'>\n",
      "transformer.h.0 <class 'dabble_gpt.Block'>\n",
      "transformer.h.0.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.0.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.0.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.0.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.0.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.0.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.0.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.0.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.0.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.0.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.1 <class 'dabble_gpt.Block'>\n",
      "transformer.h.1.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.1.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.1.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.1.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.1.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.1.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.1.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.1.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.1.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.1.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.2 <class 'dabble_gpt.Block'>\n",
      "transformer.h.2.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.2.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.2.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.2.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.2.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.2.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.2.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.2.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.2.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.2.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.3 <class 'dabble_gpt.Block'>\n",
      "transformer.h.3.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.3.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.3.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.3.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.3.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.3.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.3.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.3.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.3.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.3.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.4 <class 'dabble_gpt.Block'>\n",
      "transformer.h.4.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.4.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.4.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.4.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.4.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.4.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.4.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.4.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.4.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.4.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.5 <class 'dabble_gpt.Block'>\n",
      "transformer.h.5.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.5.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.5.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.5.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.5.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.5.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.5.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.5.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.5.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.5.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.6 <class 'dabble_gpt.Block'>\n",
      "transformer.h.6.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.6.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.6.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.6.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.6.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.6.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.6.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.6.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.6.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.6.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.7 <class 'dabble_gpt.Block'>\n",
      "transformer.h.7.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.7.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.7.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.7.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.7.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.7.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.7.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.7.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.7.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.7.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.8 <class 'dabble_gpt.Block'>\n",
      "transformer.h.8.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.8.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.8.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.8.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.8.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.8.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.8.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.8.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.8.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.8.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.9 <class 'dabble_gpt.Block'>\n",
      "transformer.h.9.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.9.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.9.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.9.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.9.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.9.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.9.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.9.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.9.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.9.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.10 <class 'dabble_gpt.Block'>\n",
      "transformer.h.10.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.10.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.10.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.10.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.10.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.10.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.10.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.10.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.10.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.10.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.11 <class 'dabble_gpt.Block'>\n",
      "transformer.h.11.ln_1 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.11.attn <class 'dabble_gpt.CausalSelfAttention'>\n",
      "transformer.h.11.attn.c_attn <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.11.attn.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.11.attn.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
      "transformer.h.11.ln_2 <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "transformer.h.11.mlp <class 'dabble_gpt.MLP'>\n",
      "transformer.h.11.mlp.c_fc <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.h.11.mlp.gelu <class 'torch.nn.modules.activation.GELU'>\n",
      "transformer.h.11.mlp.c_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "transformer.ln_f <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "lm_head <class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for name, module in gpt.named_modules():\n",
    "    print(name, type(module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd4359e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546.1333333333333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65536 / 8 / 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "70460e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scientists recently discovered a herd of fuzzy '"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = torch.tensor(token_enc.encode(\"Scientists recently discovered a herd of fuzzy \"))\n",
    "out_seq = token_enc.decode(seq.detach().numpy())\n",
    "out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67479130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'category used especially in former classifications for organisms now constituting the division Lichenes'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('lichenales')[0].definition()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
